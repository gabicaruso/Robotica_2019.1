{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade 2 - Visão Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O entregável de toda esta atividade vai ser um código-fonte em *Python*. \n",
    "\n",
    "Encorajamos vocês a fazerem vídeos demonstrando o resultado e a postar (pode ser privadamente) no YouTube\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você deve ter uma folha com o padrão anexo. \n",
    "*Dica:* Se não tiver, é possível fazer também com um tablet ou *smartphone*\n",
    " \n",
    "<img src=\"folha_atividade.png\" width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Version : 3.4.2 \n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time as t\n",
    "import sys\n",
    "import math\n",
    "print (\"OpenCV Version : %s \" % cv2.__version__)\n",
    "\n",
    "from ipywidgets import widgets, interact, interactive, FloatSlider, IntSlider\n",
    "\n",
    "import auxiliar as aux\n",
    "\n",
    "if (sys.version_info > (3, 0)): \n",
    "    # Modo Python 3\n",
    "    import importlib\n",
    "    importlib.reload(aux) # Para garantir que o Jupyter sempre relê seu trabalho\n",
    "else:\n",
    "    # Modo Python 2\n",
    "    reload(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - calibração\n",
    "\n",
    "Ouça a explicação do professor sobre o modelo de câmera *pinhole*  e desenhe a medida $f$ que separa o plano focal da pupila da câmera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detalhe como calculou $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956.2877697841726"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ho = 13.9 #distância dos centros dos círculos em centímetros\n",
    "hi = 627 #distância dos centros dos círculos na tela em pixels\n",
    "d = 21.2 #distância da tela até o final do teclado em centímetros\n",
    "\n",
    "f = (hi*d)/ho\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2\n",
    "\n",
    "Modifique um dos exemplos `draw_circles_video.py` ou `videoplay.py` para passar a ler dados da webcam e identificar o círculo magenta e o círculo ciano, usando o `inRange`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    minm = np.array([142, 30, 30])\n",
    "    maxm = np.array([192, 255, 255])\n",
    "    \n",
    "    maskm = cv2.inRange(hsv, minm, maxm) \n",
    "    \n",
    "    minc = np.array([92, 40, 40])\n",
    "    maxc = np.array([122, 255, 255])\n",
    "    \n",
    "    maskc = cv2.inRange(hsv, minc, maxc) \n",
    "\n",
    "    # Display the resulting frame\n",
    "#    cv2.imshow('mask', maskm)\n",
    "#    cv2.imshow('mask', maskc)\n",
    "\n",
    "    masks = cv2.bitwise_or(maskm, maskc)\n",
    "    juncao = cv2.bitwise_and(frame, frame, mask=masks)\n",
    "    \n",
    "    juncao_rgb = (juncao, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    cv2.imshow('frame', juncao)\n",
    "#    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumindo que a folha se mantém sempre paralela ao plano de imagem da câmera, imprima a distância entre a folha e sua câmera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obs: Partes 3, 4 e 5 juntas ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-1a492e0f11a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0md_h1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbordas_color\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# If you want to open a video, just change this path\n",
    "#cap = cv2.VideoCapture('hall_box_battery.mp4')\n",
    "\n",
    "# Parameters to use when opening the webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "lower = 0\n",
    "upper = 1\n",
    "\n",
    "# Returns an image containing the borders of the image\n",
    "# sigma is how far from the median we are setting the thresholds\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "\n",
    "    # return the edged image\n",
    "    return edged\n",
    "\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # A gaussian blur to get rid of the noise in the image\n",
    "    blur = cv2.GaussianBlur(gray,(9,9),0)\n",
    "    #blur = gray\n",
    "    # Detect the edges present in the image\n",
    "    bordas = auto_canny(blur)\n",
    "\n",
    "\n",
    "    circles = []\n",
    "#    centros = []\n",
    "\n",
    "    # Obtains a version of the edges image where we can draw in color\n",
    "    bordas_color = cv2.cvtColor(bordas, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # HoughCircles - detects circles using the Hough Method. For an explanation of\n",
    "    # param1 and param2 please see an explanation here http://www.pyimagesearch.com/2014/07/21/detecting-circles-images-using-opencv-hough-circles/\n",
    "    circles = None\n",
    "    circles=cv2.HoughCircles(bordas,cv2.HOUGH_GRADIENT,2,40,param1=50,param2=100,minRadius=5,maxRadius=60)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        for i in circles[0,:]:\n",
    "            # draw the outer circle\n",
    "            # cv2.circle(img, center, radius, color[, thickness[, lineType[, shift]]])\n",
    "            cv2.circle(bordas_color,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "            # draw the center of the circle\n",
    "            cv2.circle(bordas_color,(i[0],i[1]),2,(0,0,255),3)\n",
    "            # cv2.line(img, pt1, pt2, color[, thickness[, lineType[, shift]]])\n",
    "#            centros.append([i[0], i[1]])\n",
    "            \n",
    "        if len(circles[0]) == 2:\n",
    "            x1, y1, r1 = circles[0][0]\n",
    "            x2, y2, r2 = circles[0][1]\n",
    "            \n",
    "            x = int(x2)-int(x1)\n",
    "            y = int(y2)-int(y1)\n",
    "                                       \n",
    "            d_h1 = math.sqrt(x**2 + y**2)\n",
    "            \n",
    "            # f e h0 q foram definidos na parte 1\n",
    "            f = 956.2877697841726\n",
    "            ho = 13.9\n",
    "            \n",
    "            d = (f*ho)/d_h1\n",
    "            \n",
    "            a = math.degrees(math.atan(y/x))\n",
    "            \n",
    "            cv2.line(bordas_color, (x1, y1), (x2, y2), (255,0,0), 5)\n",
    "        \n",
    "        \n",
    "            #cv2.putText(img, text, org, fontFace, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(bordas_color,'Distance: {0}'.format(d),(0,50), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(bordas_color,'Angle: {0}'.format(a),(0,90), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Detector de circulos',bordas_color)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4\n",
    "\n",
    "Trace uma linha entre os centros do círculo magenta e do círculo ciano.\n",
    "\n",
    "Imprima na tela o ângulo entre esta linha e a horizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 5\n",
    "\n",
    "Usando transformada de Hough, desenhe um círculo sobre o círculo ciano e outro sobre o círculo magenta.\n",
    "\n",
    "**Desafio bônus**: ser capaz de eliminar circulos espúrios (aqueles que não são os da folha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 6\n",
    "\n",
    "Usando `SIFT`, identifique o escrito *Insper* na folha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from math import pi\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número mínimo de pontos correspondentes\n",
    "MIN_MATCH_COUNT = 5\n",
    "\n",
    "imagem = cv2.imread('insper.jpg',0) # Imagem do cenario - puxe do video para fazer isto\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n",
      "Matches 0\n",
      "Not enough matches are found - 0/5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Cria o detector SIFT\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# Encontra os pontos únicos (keypoints) nas duas imagems\n",
    "kp1, des1 = sift.detectAndCompute(imagem ,None)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Imagem de saída\n",
    "    out = frame_rgb.copy()\n",
    "    \n",
    "    kp2, des2 = sift.detectAndCompute(imagem, None)\n",
    "    \n",
    "    cv2.imshow(\"captura\", out)\n",
    "    \n",
    "    # Configurações do algoritmo FLANN que compara keypoints e ver correspondências - não se preocupe com isso\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    # Configura o algoritmo de casamento de features que vê *como* o objeto que deve ser encontrado aparece na imagem\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    # Tenta fazer a melhor comparacao usando o algoritmo\n",
    "    matches = flann.knnMatch(des1,k=2)\n",
    "\n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "\n",
    "    print(\"Matches\", len(good))\n",
    "            \n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        # Separa os bons matches na origem e no destino\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "        # Tenta achar uma trasformacao composta de rotacao, translacao e escala que situe uma imagem na outra\n",
    "        # Esta transformação é chamada de homografia \n",
    "        # Para saber mais veja \n",
    "        # https://docs.opencv.org/3.4/d9/dab/tutorial_homography.html\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "\n",
    "\n",
    "\n",
    "        h,w = imagem.shape\n",
    "        # Um retângulo com as dimensões da imagem original\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "\n",
    "        # Transforma os pontos do retângulo para onde estao na imagem destino usando a homografia encontrada\n",
    "        dst = cv2.perspectiveTransform(pts,M)\n",
    "\n",
    "\n",
    "        # Desenha um contorno em vermelho ao redor de onde o objeto foi encontrado\n",
    "        img2b = cv2.polylines(frame,[np.int32(dst)],True,(255,0,0),3, cv2.LINE_AA)\n",
    "\n",
    "    else:\n",
    "        print(\"Not enough matches are found - %d/%d\" % (len(good),MIN_MATCH_COUNT))\n",
    "        matchesMask = None\n",
    "\n",
    "    draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                       singlePointColor = None,\n",
    "                       matchesMask = matchesMask, # draw only inliers\n",
    "                       flags = 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('SIFT',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atividade2.ipynb             folha_atividade.png\r\n",
      "RinTinTin.jpg                hall_box_battery1.jpg\r\n",
      "SIFT Features.ipynb          hall_box_battery_1024.mp4\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                  \u001b[31mhoughlines.py\u001b[m\u001b[m\r\n",
      "aula2_OpenCV_Filtragem.ipynb insper-nome.png\r\n",
      "auxiliar.py                  insper.jpg\r\n",
      "box.png                      insperlogo.jpeg\r\n",
      "box_in_scene.png             sift.py\r\n",
      "coke-cans.jpg                videoplay.py\r\n",
      "draw_circles_video.py        videoplay_canny.py\r\n",
      "folha_atividade.pdf\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gabrielacaruso/Documents/Insper/3 Semestre/Robótica Computacional/robot19/aula_02\r\n"
     ]
    }
   ],
   "source": [
    "!pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
